---
layout: post
title: "Technological Singularity"
date: 2013-08-30 12:55
comments: true
published: false
categories: Science
---

Arguably, one of the most puzzling aspect of human as a species is the intelligence. Human possesses logic, abstract thought, and self-awareness at much higher level compared to other species on earth.

How does the brain formulates thought? The human cognition is a mystery that intrigues many scientists. How our mind really works is not well understood and still heavily researched. Many people proposed that the mind is actually detached from the body (the [dualism](https://en.wikipedia.org/wiki/Dualism_%28philosophy_of_mind%29)).

Emulating the human intelligence inside a computer is a dream of many computer scientists. Even thought the human mind is not fully understood yet, many specific aspects of human intelligence are already implemented as computer programs. These programs, commonly refered as [Artificial Intelligence (AI)](http://en.wikipedia.org/wiki/History_of_artificial_intelligence), are used to solve specific tasks. Compared to the human mind, the current Artificial Intelligences are still very limited. They possess limited logic, without any abstract thought and self-awareness. Thus, it's common to refer to these form of AI as Weak AI.

Constructing a general purpose AI (the mythical [Strong AI](http://en.wikipedia.org/wiki/Strong_AI)) is currently not possible. Not only that we don't fully understand how the human intelligence really works, our supercomputers are not that fast yet. Most supercomputers that available today are actually a bunch (well, thousands) of server nodes with commodity processors (usually Intel Xeon processor), a huge RAM (>128GB per node), and a superfast network (usually Infiniband) to connect those nodes. The combined computing power is really large, but only useful if the target problem can be parallelized. For serial computation, the supercomputer is only marginally faster than your laptop. It's possible that we'll need a huge serial processing power (in addition of also huge parallel processing power) to make the Strong AI practical, assuming we're finally capable of building the Strong AI in the first place.

Imagine that we, against all odds, are finally capable of building a true artificial intelligence. Not just a weak AI, but a general purpose Strong AI. Since the Strong AI is capable of doing any task that the humans capable of, it's logical that the AI can construct another AI. Given enough time and resources, the AI might even capable of creating an even better AI, rendering itself obselete. Eventually, the new AI would replace the old AI.

Since the new AI is better than the old AI, it's also logical that the new AI would have the capability to build another AI. Since the new AI is better, it's possible that it could eventually create an entirely new AI that better than itself, rendering itself obselete, just like the old AI.

The cycle continue until at one point an AI that possesses intelligence that vastly surpass the human mind is finally formed. This is what we called the [Technological Singularity](https://en.wikipedia.org/wiki/Technological_singularity).

When (if) we finally reached the singularity, our society would not be the same anymore.


Can We Survive the Singularity?
-------------------------------

What would happen if computers are finally smarter than any human being?

What would you do if you suddenly lost your job because your industry suddenly became obselete, completely replaced by computers?

During last industrial revolution, a great many people suddenly lost their job from the textile industry, replaced by machines capable of producing textile at much higher quantity and better quality. When the singularity happen, the computer can replace anyone, just like those workers that replaced by steam engines during the last industrial revolution. It would not make any economical sense anymore to hire a human. If a company still employing humans, its competitor can easily beat them by employing computers. The computer can works long hours without compensation and vacation. In a sense, the computer is a slave worker, only that it doesn't mind being so.

What would you do if you live in such world? If you know that no matter how hard you study you'll never be as smart as a computer purchased from a store next door, would you spent a significant portion of your life to pursue a Ph.D.? Would you became an artist instead? What if the computer can be an artist too?

Also, when the computers are smarter than any human being, who could guarantee that they'll stay content being our slave worker? What if they decide that the world would be a better place without us? After all, we did pollute this world and drove many species to extinction. Skynet, is that you?


Three Laws of Robotics
----------------------

Chance that you're already know this stuff (possibly from [I, Robot](http://www.imdb.com/title/tt0343818/) movie):

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.

