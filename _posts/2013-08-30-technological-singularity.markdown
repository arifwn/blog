---
layout: post
title: "Technological Singularity"
date: 2013-08-30 12:55
comments: true
published: false
categories: Science
---

Arguably, one of the most puzzling aspect of human as a species is the intelligence. Human possesses logic, abstract thought, and self-awareness at much higher level compared to other species on earth.

How does the brain formulates thought? The human cognition is a mystery that intrigues many scientists. How our mind really works is not well understood and still heavily researched. Many people proposed that the mind is actually detached from the body (the [dualism](https://en.wikipedia.org/wiki/Dualism_%28philosophy_of_mind%29)).

Emulating the human intelligence inside a computer is a dream of many computer scientists. Even thought the human mind is not fully understood yet, many specific aspects of human intelligence are already implemented as computer programs. These programs, commonly refered as [Artificial Intelligence (AI)](http://en.wikipedia.org/wiki/History_of_artificial_intelligence), are used to solve specific tasks. Compared to the human mind, the current Artificial Intelligences are still very limited. They possess limited logic, without any abstract thought and self-awareness. Thus, it's common to refer to these form of AI as Weak AI.

Constructing a general purpose AI (the mythical [Strong AI](http://en.wikipedia.org/wiki/Strong_AI)) is currently not possible. Not only that we don't fully understand how the human intelligence really works, our supercomputers are not that fast yet. Most supercomputers that available today are actually a bunch (well, thousands) of server nodes with commodity processors (usually Intel Xeon processor), a huge RAM (>128GB per node), and a superfast network (usually Infiniband) to connect those nodes. The combined computing power is really large, but only useful if the target problem can be parallelized. For serial computation, the supercomputer is only marginally faster than your laptop. It's possible that we'll need a huge serial processing power (in addition of also huge parallel processing power) to make the Strong AI practical, assuming we're finally capable of building the Strong AI in the first place.

Imagine that we, against all odds, are finally capable of building a true artificial intelligence. Not just a weak AI, but a general purpose Strong AI. Since the Strong AI is capable of doing any task that the humans capable of, it's logical that the AI can construct another AI. Given enough time and resources, the AI might even capable of creating an even better AI, rendering itself obselete. Eventually, the new AI would replace the old AI.

Since the new AI is better than the old AI, it's also logical that the new AI would have the capability to build another AI. Since the new AI is better, it's possible that it could eventually create an entirely new AI that better than itself, rendering itself obselete, just like the old AI.

And the cycle continue...

This is what we called the [Technological Singularity](https://en.wikipedia.org/wiki/Technological_singularity).